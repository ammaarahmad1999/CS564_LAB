# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s6-x_BdPHfYdbwlA0R4XboINf9Te9orQ
"""

import numpy as np
from sklearn import datasets
import queue
import pandas as pd
from itertools import cycle, islice
from sklearn.preprocessing import StandardScaler

# Find all neighbour points at epsilon distance
def neighbour_points(data, pointId, epsilon):
    points = []
    for i, x in enumerate(data):
        # Euclidian distance
        if np.linalg.norm([a_i - b_i for a_i, b_i in zip(x, data[pointId])]) <= epsilon:
            points.append(i)
    return points

# Fit data into the dbscan model
def fit(data, Eps, MinPt):
    
    # initialize all points as outliers
    length = len(data)
    label = [0] * length
    count = []

    # initilize list for core/border points
    core = []
    border = []

    border_points=[]
    core_points=[]

    # Find the neighbours of each individual point
    for i in range(length):
        count.append(neighbour_points(data, i, Eps))

    # Find all the core points, border points and outliers
    for i, x in enumerate(count):
        if (len(x) >= MinPt):
            label[i] = -1
            core.append(i)
        else:
            border.append(i)

    for i in border:
        for j in count[i]:
            if j in core:
                label[i] = -2
                break

    cluster = 1
    
    # Here we use a queue to find all the neighbourhood points of a core point and find the indirectly reachable points
    # We are essentially performing Breadth First search of all points which are within Epsilon distance for each other
    for i, x in enumerate(label) :
        q=queue.Queue()
        if (x == -1):
            x = cluster
            if cluster == 1:
              core_points.append(i)
            
            for x in count[i]:
                if (label[x] == -1):
                    q.put(x)
                    label[x] = cluster
                    if cluster == 1:
                      core_points.append(x)
                elif (label[x] == -2):
                    label[x] = cluster
                    if cluster == 1:
                      border_points.append(x)
            
            while not q.empty():
                neighbors = count[q.get()]
                for y in neighbors:
                    if (label[y] == -1):
                        label[y] = cluster
                        if cluster == 1:
                          core_points.append(y)
                        q.put(y)
                    if (label[y] == -2):
                        label[y] = cluster
                        if cluster == 1:
                          border_points.append(y)
            
            cluster += 1
    
    cluster -= 1
    core_points.sort()
    border_points.sort()

    return cluster, core_points, border_points

# read data from file
df = pd.read_csv("diabetes1.arff")

#remove the last column according to instruction in assignment
df.drop(columns=['class'],inplace=True)

#convert data into list
dataset = df.astype(float).values.tolist()

# normalize dataset
normalized_dataset = StandardScaler().fit_transform(dataset)

# labels contains the cluster assignments of each point
clusters, core_points, border_points = fit(normalized_dataset, 2, 5)

#print number of clusters
print("No. of clusters = ",clusters)

# print the core points of first cluster
print("Core points (for first cluster) : ")
print(core_points)

# print the border points of first cluster
print("Border points (for first cluster) : ")
print(border_points)
